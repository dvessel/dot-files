#!/usr/bin/env zsh

local cmd=${1:-run} supported_cmd=( run stop show cp rm )

if (( $supported_cmd[(I)$cmd] )); then
  if [[ -n $1 ]]; then
    shift
  fi

  local list fzf_args
  fzf_args=( --prompt="â¯ ollama $cmd " --header-lines=1 )

  case $cmd in
    run)
      # ignore embedding models when running directly.
      list=`ollama ls | grep -vi "-embed"`
    ;;
    stop)
      list=`ollama ps`
      fzf_args+=--multi
    ;;
    rm)
      list=`ollama ls`
      fzf_args+=--multi
    ;;
    pull)
      # TODO: pull from this unofficial source.
      # https://craigahobbs.github.io/ollama-chat/models/models.json
    ;;
    *)
      list=`ollama ls`
    ;;
  esac

  local model=($( print -- $list | fzf $fzf_args | cut -d ' ' -f1 ))

  if [[ -n $model ]]; then
    print "ollama $cmd $model $@"
    ollama $cmd $model $@
  fi
else
  print "Unsupported command. $0:t only accepts the following:\n $supported_cmd" >&2
  return 1
fi
